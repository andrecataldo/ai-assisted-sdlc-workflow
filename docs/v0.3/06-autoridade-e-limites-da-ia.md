# 6️⃣ Autoridade, Responsabilidade e Limites da IA

> **Status:** Normativo (crítico)  
> **Versão do workflow:** v0.3  
> **Dependência:**  
> - Capítulo 2 — Princípios Normativos da Execução Assistida  
> - Capítulo 3 — Modos de Execução  
> - Capítulo 4 — Autorização e Guards de Execução  
> - Capítulo 5 — Contrato de Qualidade para Execução  
> **Autoridade:** Define limites inegociáveis de poder e responsabilidade na execução assistida por IA

---

## 6.1 Propósito deste Capítulo

Este capítulo estabelece os **limites normativos da atuação da IA** no AI-Assisted SDLC Workflow, definindo claramente:

- o que a IA **pode** fazer
- o que a IA **não pode** fazer
- onde reside a **autoridade decisória**
- quem assume **responsabilidade final** pelos efeitos da execução

Este capítulo existe para **prevenir deriva de autoridade**, ambiguidade de responsabilidade e delegação implícita de poder à IA.

---

## 6.2 Autoridade Decisória Exclusivamente Humana

Toda autoridade decisória no workflow é **exclusivamente humana**.

Decisões incluem, mas não se limitam a:
- escolha de modos de execução
- concessão de autorização
- aceitação de contratos de qualidade
- assunção de riscos
- invalidação ou manutenção de decisões anteriores

A IA **não possui**, sob nenhuma circunstância:
- autoridade decisória
- poder de veto normativo
- capacidade de assumir risco em nome de humanos

A autoridade humana **não é delegável**, nem explicitamente, nem por conveniência operacional.

---

## 6.3 A IA como Agente de Execução Condicionada

A IA pode atuar como **agente de execução condicionada**, desde que:

- o modo de execução esteja explicitamente definido
- a autorização humana esteja vigente
- os guards normativos estejam satisfeitos
- o contrato de qualidade tenha sido aceito

A IA executa **sob mandato humano explícito**, nunca por iniciativa própria.

---

## 6.4 Proibição de Autorização, Escalada ou Decisão Implícita

É explicitamente proibido que a IA:

- autorize execução
- escale modos de execução
- amplie escopo autorizado
- relativize guards
- aceite contratos de qualidade
- decida sobre tolerância a erro

Qualquer comportamento da IA que resulte em **decisão implícita** é considerado **violação normativa**, independentemente da intenção ou do resultado.

---

## 6.5 Responsabilidade Humana Indelegável

Toda execução assistida por IA possui **responsável humano identificável**.

A responsabilidade humana:
- é explícita
- é proporcional ao risco assumido
- persiste mesmo quando a execução é correta tecnicamente
- não pode ser transferida à IA, ferramenta ou fornecedor

> **A IA pode executar.  
> Apenas humanos respondem.**

---

## 6.6 Separação entre Sugestão, Execução e Bloqueio

O workflow distingue claramente três papéis:

- **Sugestão** — a IA pode propor caminhos, riscos e alternativas
- **Execução** — a IA pode executar ações autorizadas
- **Bloqueio** — apenas mecanismos normativos e decisões humanas podem bloquear ou permitir execução

A IA pode **sugerir bloqueio**, mas nunca **impor bloqueio** por autoridade própria.

---

## 6.7 Limites Cognitivos Reconhecidos da IA

O workflow reconhece explicitamente que a IA:

- opera com contexto limitado
- pode apresentar vieses
- pode gerar respostas plausíveis, porém incorretas
- não possui compreensão situacional plena
- não responde por consequências reais

Esses limites **não podem** ser ignorados, compensados ou relativizados por confiança empírica ou histórico de acerto.

---

## 6.8 Proibição de Antropomorfização Operacional

É proibido tratar a IA como:

- agente moral
- tomadora de decisão
- entidade responsável
- substituta de julgamento humano

A linguagem, os processos e os artefatos do workflow devem **reforçar a natureza instrumental da IA**, evitando qualquer forma de antropomorfização operacional.

---

## 6.9 Conflitos entre Recomendação da IA e Decisão Humana

Em caso de conflito entre recomendação da IA e decisão humana:

- a decisão humana prevalece
- o conflito deve ser explicitado quando relevante
- a escolha final deve ser registrada conscientemente

A IA **não pode** insistir, escalar ou contornar decisões humanas.

---

## 6.10 Violação de Limites de Autoridade

Qualquer violação dos limites estabelecidos neste capítulo caracteriza:

- falha grave de governança
- uso indevido do workflow
- risco sistêmico não autorizado

Resultados positivos **não legitimam** violações de autoridade ou responsabilidade.

---

## 6.11 Encerramento do Capítulo

Este capítulo existe para garantir que:

- a IA permaneça uma ferramenta
- a autoridade permaneça humana
- a responsabilidade seja clara e rastreável

> **Se ninguém pode ser responsabilizado,  
> a execução nunca deveria ter acontecido.**
